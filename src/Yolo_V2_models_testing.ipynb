{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/jupyter/Deep_Learning/src/YOLO/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Reshape, Input, Activation, Conv2D, GlobalMaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dense, Lambda, ZeroPadding2D, Dropout, DepthwiseConv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from Yolo_V2_utils import *\n",
    "from Yolo_V2_extractors import *\n",
    "from Yolo_V2_preprocessing import *\n",
    "from Yolo_V2_detection_head import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECT = 'Plate'          # Plate / Car / Number\n",
    "BACKEND = 'SqueezeNet'    # DarkNet, MobileNet, SqueezeNet\n",
    "\n",
    "ROOT_DIR = '/root/jupyter/'\n",
    "DATA_DIR = ROOT_DIR + 'Deep_Learning/data/'\n",
    "MODEL_DIR = ROOT_DIR + 'Deep_Learning/models/'\n",
    "BACKEND_DIR = ROOT_DIR + 'Deep_Learning/backends/'\n",
    "\n",
    "FULL_YOLO_BACKEND_PATH  = BACKEND_DIR + \"yolo_v2.weights\"\n",
    "SQUEEZENET_BACKEND_PATH = BACKEND_DIR + \"squeezenet_backend.h5\"\n",
    "MOBILENET_BACKEND_PATH  = BACKEND_DIR + \"mobilenet_backend.h5\"\n",
    "\n",
    "TRAIN_VALID_PROP = 0.8    # Fraction des données qui seront utilisées pour l'entrainement\n",
    "INPUT_SIZE = 640          # Dimension maximale de l'image\n",
    "LABELS = [OBJECT]         # Liste des objets que doit YOLO considérer lors de la détection et entrainement\n",
    "MAX_BOX_PER_IMAGE = 1     # GENERATED 1, MOROCCAN 26\n",
    "OBJ_THRESH = 0.5          # Valeur minimale de sûreté/fidélité/confidence pour considérer la détéction positive\n",
    "NMS_THRESH = 0.5          # Valeur minimale de sûreté/fidélité/confidence pour considérer la détéction positive\n",
    "\n",
    "ANCHORS = [1.40,0.55, 2.36,0.96, 3.47,1.42, 4.47,1.93, 5.78,2.40, 6.68,3.27, 7.98,2.70, 8.58,3.70, 9.08,4.67]\n",
    "\n",
    "# GENERATED 320 [1.40,0.55, 2.36,0.96, 3.47,1.42, 4.47,1.93, 5.78,2.40, 6.68,3.27, 7.98,2.70, 8.58,3.70, 9.08,4.67]\n",
    "# GENERATED 640 [2.74,1.10, 4.39,1.83, 6.31,2.65, 8.47,3.61, 11.02,4.59, 12.80,6.18, 15.97,5.34, 16.70,7.28, 18.21,9.28]\n",
    "# MOROCCAN 1024 [1.61,0.91, 5.37,2.12, 6.37,5.60, 7.61,2.80, 9.20,4.60, 9.89,3.00, 11.66,3.39, 12.68,4.25, 16.94,6.37]\n",
    "# MOROCCAN RESIZED 512 [0.74,0.42, 2.28,0.93, 3.22,2.92, 3.61,1.25, 4.13,1.81, 5.12,2.64, 5.30,1.53, 6.14,1.91, 9.07,3.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 39)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 640, 640, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "squeezenet (Model)              (None, 39, 39, 512)  722496      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "DetectionLayer (Conv2D)         (None, 39, 39, 54)   27702       squeezenet[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 39, 39, 9, 6) 0           DetectionLayer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1, 1, 1, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 39, 39, 9, 6) 0           reshape_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 750,198\n",
      "Trainable params: 750,198\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(BACKEND, INPUT_SIZE, LABELS, MAX_BOX_PER_IMAGE, ANCHORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = MODEL_DIR + 'Plate_SqueezeNet_GENERATED_DATASET_Final.h5'\n",
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9c9cad73d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEST_DIR' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(20, 20))\n",
    "test_imgs = os.listdir(TEST_DIR)\n",
    "\n",
    "columns = 2\n",
    "rows = 2\n",
    "i = 1\n",
    "passed = []\n",
    "\n",
    "while i < rows*columns +1:\n",
    "    rand_numb = np.random.randint(0,len(test_imgs)-1)\n",
    "    if rand_numb in passed :\n",
    "        continue\n",
    "    try:\n",
    "        IMAGE_PATH = TEST_DIR + test_imgs[rand_numb]\n",
    "        image = cv2.imread(IMAGE_PATH)\n",
    "        boxes = model.predict(image)\n",
    "        image = draw_boxes(image, boxes, LABELS)\n",
    "        plt_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(plt_image)\n",
    "        passed += [rand_numb]\n",
    "        i += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
